{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqtPUafmApG5"
   },
   "source": [
    "# Network Friendly Recommendations Project: 2nd assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You need to be able to solve the Q-learning problem (i.e. you don't know $u_{min}$ and $a$) again, but now you need to make it work for large $K$ (e.g. 1000s) and larger $N$ (e.g. up to $N$ = 5 or 10).\n",
    "- If you learned anything from this project, and the class, it is clear that no \"tabular\" solution can work here. You'll need tricks and approximations. What tricks, it's up to you.\n",
    "- Some initial ideas I have provided are\n",
    "    - what we have done to deal with large $N$ (see my team's paper[$^{[\\ast]}$](https://hal.science/hal-03578013/document), cited in the description), but this is in the MDP case, not Q-learning;\n",
    "    - what Google has tried to deal with this problem in a paper[$^{[\\ast]}$](https://arxiv.org/pdf/1905.12767.pdf) I also cite there;\n",
    "    - other (Deep/Approximate) RL methods you can think of, or find, to deal with your main problem, the large action space.\n",
    "      [Deep Q-learning with experience replay](https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf)\n",
    "- You could even try to model some other user type (e.g. someone that has \"memory\" of bad recommendations for more than one content - i.e., you give me one recommendations below $u_{min}$, and I might keep ignoring your good recommendations, for X contents in the future, with some probability...until you regain my trust).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp5UAOWzUghI"
   },
   "source": [
    "## Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8QwChHYuUfkD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, copy, math, random\n",
    "import matplotlib.cm as cm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKFEcvdSUZeU"
   },
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ekvJToSzBRxU"
   },
   "outputs": [],
   "source": [
    "# Print u matrix with colors based on relations\n",
    "def print_matrix(matrix,u_min):\n",
    "    RED = '\\033[91m'  # ANSI escape code for red text\n",
    "    YELLOW = '\\033[93m'  # ANSI escape code for yellow text\n",
    "    RESET = '\\033[0m'  # ANSI escape code to reset the text color\n",
    "\n",
    "    for i, row in enumerate(matrix):\n",
    "        for j, element in enumerate(row):\n",
    "            if i == j:\n",
    "                print(f\"{YELLOW}{element:.3f}{RESET}\", end=\" \")  # Print diagonal element in yellow\n",
    "            elif element < u_min:\n",
    "                print(f\"{RED}{element:.3f}{RESET}\", end=\" \")  # Print in red if smaller than min_value\n",
    "            else:\n",
    "                print(f\"{element:.3f}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "# Create a symmetric matrix\n",
    "def create_symmetric_matrix(K):\n",
    "    matrix = [[random.random() if i != j else 0 for j in range(K)] for i in range(K)]\n",
    "\n",
    "    # Make the matrix symmetric by copying the upper triangle to the lower triangle\n",
    "    for i in range(K):\n",
    "        for j in range(i+1, K):\n",
    "            matrix[j][i] = matrix[i][j]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Choose which C of the K items will be cached\n",
    "def random_cached_items(K, C):\n",
    "    reward = [-1] * K  # Create a vector of length K with all 0 elements\n",
    "\n",
    "    # Select C random indices\n",
    "    indices = random.sample(range(K), C)\n",
    "\n",
    "    # Set the selected indices to True\n",
    "    for index in indices:\n",
    "        reward[index] = 0\n",
    "\n",
    "    return reward\n",
    "\n",
    "# Random recommendation for current content watched\n",
    "def random_recommendation(K, N, curr_content):\n",
    "    recom = []  # Create an empty vector\n",
    "\n",
    "    for _ in range(N):\n",
    "        random_number = random.randint(0, K-1)\n",
    "        while random_number == curr_content or random_number in recom:  # Check if random number is equal to curr_content or is already in recom\n",
    "            random_number = random.randint(0, K-1)  # Generate a new random number\n",
    "        recom.append(random_number)\n",
    "    recom.sort()\n",
    "    return recom\n",
    "\n",
    "# Are all the recommended videos relevant to the current content being watched?\n",
    "def all_relevant(N, curr_content, u, recom, u_min):\n",
    "    all_relevant = True\n",
    "    for i in range(N):\n",
    "        if u[curr_content][recom[i]] < u_min: # Check if at least one is irrelevant\n",
    "            all_relevant = False                # If one is irrelevant return false\n",
    "            break\n",
    "    return all_relevant\n",
    "\n",
    "# User chooses the next video to watch\n",
    "def user_chooses(K, N, q, u, u_min, a, recom, curr_content):\n",
    "    if random.uniform(0, 1) > q:\n",
    "        if all_relevant(N, curr_content, u, recom, u_min):  # If all recommended are relevant\n",
    "            if random.uniform(0, 1) < a:  # User chooses one of the recommended\n",
    "                new_content = recom[random.randint(0, N-1)]\n",
    "            else:\n",
    "                new_content = random.choice([x for x in range(K) if x != curr_content])\n",
    "        else:                                               # If at least one recommended isn't relevant\n",
    "            new_content = random.choice([x for x in range(K) if x != curr_content])\n",
    "    else:\n",
    "        new_content = -1\n",
    "    return new_content\n",
    "\n",
    "# Environment probability of user moving to next content given that he watches current content\n",
    "# and he is being recommended the list recom\n",
    "def env_prob(K, N, u, u_min, a, recom, curr_content, next_content):\n",
    "    if curr_content==next_content:  # No possibility that the user watches the same content consequently\n",
    "        env_prob = 0.0\n",
    "    else:\n",
    "        if all_relevant(N, curr_content, u, recom, u_min):  # If all recommended are relevant\n",
    "        #print(\"All Relevant\")\n",
    "            if next_content in recom:     # If the next content was recommended\n",
    "                env_prob = a/N + (1-a)/(K-1)\n",
    "            else:                         # If the next content wasn't recommended\n",
    "                env_prob = (1-a)/(K-1)\n",
    "        else:                           # If at least one recommended isn't relevant\n",
    "            #print(\"Not Relevant\")\n",
    "            env_prob = 1/(K-1)\n",
    "    return env_prob\n",
    "\n",
    "# All possible recommendations for state s\n",
    "def possible_recom(K, N, s):\n",
    "    items = list(range(K))\n",
    "    items.remove(s)  # Remove 's' from the list of items\n",
    "\n",
    "    def generate_combinations(curr_set, remaining_items):\n",
    "        if len(curr_set) == N:\n",
    "            return [curr_set]\n",
    "\n",
    "        all_combinations = []\n",
    "        for i, item in enumerate(remaining_items):\n",
    "            new_set = curr_set + [item]\n",
    "            new_remaining = remaining_items[i+1:]\n",
    "            all_combinations.extend(generate_combinations(new_set, new_remaining))\n",
    "\n",
    "        return all_combinations\n",
    "\n",
    "    combinations = generate_combinations([], items)\n",
    "    return list(map(list, combinations))\n",
    "\n",
    "# All possible recommendations for all states\n",
    "def all_states_possible_recom(K, N):\n",
    "\n",
    "    all_combinations = []\n",
    "    for s in range(K):\n",
    "        state_combination = possible_recom(K, N, s)\n",
    "        all_combinations.append(state_combination)\n",
    "\n",
    "    return all_combinations\n",
    "\n",
    "# Run \"sessions_num\" Monte Carlo episodes and compute the mean loss and the total loss\n",
    "def monte_carlo_sessions(sessions_num, policy, reward, K, N, u_min, a, q, u):\n",
    "    print(\"> Running Monte Carlo sessions...\")\n",
    "    total_loss = 0\n",
    "    content_watched = 0\n",
    "    for _ in range(sessions_num):\n",
    "        curr_content = random.randint(0, K-1) # The first item viewed is random\n",
    "\n",
    "        while True:\n",
    "            recom = policy[curr_content]  # Recommend N items based on the policy\n",
    "            curr_content = user_chooses(K, N, q, u, u_min, a, recom, curr_content)\n",
    "            if curr_content == -1:\n",
    "                break\n",
    "            if reward[curr_content]==-1:\n",
    "                total_loss += 1\n",
    "            content_watched+=1\n",
    "\n",
    "    if content_watched == 0:\n",
    "        mean_loss = 0\n",
    "    else:\n",
    "        mean_loss = total_loss/content_watched\n",
    "\n",
    "    return mean_loss, total_loss\n",
    "\n",
    "# Find all the values above u_min\n",
    "def find_values_above_min(matrix, u_min):\n",
    "    result = []\n",
    "    for i, row in enumerate(matrix):\n",
    "        row_result = []\n",
    "        for j, value in enumerate(row):\n",
    "            if value > u_min:\n",
    "                row_result.append(j)\n",
    "        result.append(row_result)\n",
    "    return result\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "def create_matrix(data):\n",
    "    K = len(data)\n",
    "    N = len(data[0])\n",
    "\n",
    "    matrix = [[None] * N for _ in range(K)]\n",
    "\n",
    "    for i in range(K):\n",
    "        matrix[i] = list(data[i])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def create_tuple_list(matrix):\n",
    "    K = len(matrix)\n",
    "    N = len(matrix[0])\n",
    "\n",
    "    tuple_list = []\n",
    "\n",
    "    for i in range(K):\n",
    "        rounded_values = [int(value) for value in matrix[i]]\n",
    "        tuple_list.append(rounded_values)\n",
    "\n",
    "    return tuple_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkbhZ5fGA2Dc"
   },
   "source": [
    "## Environment (Content Catalogue):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pA6edJp8DHtr",
    "outputId": "a419fc15-685e-4fce-dfd0-8faa8e5d84a5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, 0, -1, 0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 0, -1, 0, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, -1, 0, -1, -1, -1, -1, 0, -1, 0, -1, 0, -1]\n"
     ]
    }
   ],
   "source": [
    "K = 100      # Number of content items\n",
    "u_min = 0.5 # Minimum below which two contents are \"irrelevant\"\n",
    "C = int(np.floor(0.2*K))   # Number of cached content items\n",
    "u = create_symmetric_matrix(K)        # Create the matrix of relativity\n",
    "reward = random_cached_items(K, C) # Create a vector that checks if the given item is cached\n",
    "#print_matrix(u,u_min)\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjrY85SrDVyH"
   },
   "source": [
    "## Environment (User Model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jo_0hidUEJjk",
    "outputId": "025b9b2c-7058-4b35-9bf0-0fc167f9ad03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 34, 56, 31, 28, 16, 12, 68, 59, 51, 91, 85, 72, 80, 82, 72, 93, 90, 22, 90, 21, 44, 13, 97, 0, 71, 55, 6, 28, 99, 93, 79, 20, 46, 83, 20, 8]\n"
     ]
    }
   ],
   "source": [
    "N = 10         # Number of recommended content items\n",
    "q = 0.05      # Probability of a session ending\n",
    "a = 1         # Probability of choosing a recommended content item\n",
    "round = 0     # Number of content item viewed during this session\n",
    "history = []  # The history of content items viewed during this session\n",
    "curr_content = random.randint(0, K-1) # The first item viewed is random\n",
    "history.append(curr_content)  # Append first item in history\n",
    "\n",
    "while True:\n",
    "    #print(\"Round: \"+str(round))\n",
    "    #print(\"Current content: \"+str(curr_content))\n",
    "    #### THIS WILL BE REPLACED BY OUR ALGORITHMS ####\n",
    "    recom = random_recommendation(K, N, curr_content)  # Recommend N random items\n",
    "    #################################################\n",
    "    #print(\"Recommendation: \"+str(recom))\n",
    "    curr_content = user_chooses(K, N, q, u, u_min, a, recom, curr_content)\n",
    "    if curr_content == -1:\n",
    "        break\n",
    "    history.append(curr_content)\n",
    "    round+=1\n",
    "\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15579278510796 actions per state\n",
      "Q table should be a 100x15579278510796 table\n"
     ]
    }
   ],
   "source": [
    "# Number of combinations\n",
    "comb = (int)(math.comb(K-1, N))\n",
    "print(\"There are \" + str(comb) + \" actions per state\")\n",
    "print(\"Q table should be a \" + str(K) + \"x\" + str(comb) + \" table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_label = 0\n",
    "theta_main = random.random()\n",
    "theta_pctr = random.random()\n",
    "D_training = \n",
    "\n",
    "T = 10^6     # Number of iterations\n",
    "M = 10^2     # Interval to update label network\n",
    "for i in range(1,T):\n",
    "    if i % M == 0:\n",
    "        theta_label = theta_main\n",
    "    for j in \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
